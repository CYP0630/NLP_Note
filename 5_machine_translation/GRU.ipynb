{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS584 Homework 5: Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq: GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* English to French"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparationÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load_doc: loading file \n",
    "to_line: cutting the the whole file to line by line\n",
    "clean_data: remove the symble, url, or other irrevalent information \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def to_line(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return lines\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('utf-8', 'ignore')\n",
    "        #print(line)\n",
    "        line = line.decode('UTF-8')\n",
    "            \n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "            \n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "            \n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "            \n",
    "         # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        #print(line)\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "            \n",
    "        # store as string\n",
    "        cleaned.append(' '.join(line))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentencens match with French sentences \n",
      "\n",
      "English sentence: 2007723 \n",
      "\n",
      "French sentence: 2007723 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the first 30000 sentences to contruct dataset\n",
    "data_len = 30000\n",
    "\n",
    "en = load_doc('europarl-v7.fr-en.en')\n",
    "en_lines = to_line(en)\n",
    "fr = load_doc('europarl-v7.fr-en.fr')\n",
    "fr_lines = to_line(fr)\n",
    "\n",
    "if len(en_lines) == len(fr_lines):\n",
    "    print('English sentencens match with French sentences \\n')\n",
    "    print('English sentence:', len(en_lines), '\\n')\n",
    "    print('French sentence:', len(fr_lines), '\\n')\n",
    "else :\n",
    "    print('English sentencens does not match with French sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning english part and french part \n",
    "clean_en = clean_data(en_lines)[0:data_len]\n",
    "clean_fr = clean_data(fr_lines)[0:data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i should also like to make a few comments firstly mr berend regarding the assessment you have made of this sixth periodic report\n",
      "je voudrais a mon tour faire quelques observations dabord sur le jugement que vous portez monsieur le rapporteur sur ce sixieme rapport periodique\n"
     ]
    }
   ],
   "source": [
    "clean_en = np.array(clean_en)\n",
    "clean_fr = np.array(clean_fr)\n",
    "\n",
    "# A showcase \n",
    "print(clean_en[700])\n",
    "print(clean_fr[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (30000,)\n",
      "Length of target_texts: (30000,)\n",
      "max length of input  sentences: 32\n",
      "max length of target sentences: 34\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_en\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_fr]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))\n",
    "\n",
    "#This dataset includes lots of long sentence\n",
    "#But, if we set max length with a large number, CPU cannot handle that, so we set max_encode is 32\n",
    "#Becuase we add '\\t' and '\\n' to target, so the max_decode is 34\n",
    "max_encoder_seq_length = 32 \n",
    "max_decoder_seq_length = 34\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text to Sequence\n",
    "* One-hot embedding the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (30000, 32)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (30000, 34)\n",
      "shape of target_token_index: 29\n"
     ]
    }
   ],
   "source": [
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, \n",
    "                                                      input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, \n",
    "                                                       target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) +1\n",
    "num_decoder_tokens = len(target_token_index) +1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(sequences, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = np.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 32, 28)\n",
      "(30000, 34, 30)\n",
      "(30000, 34, 30)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = np.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Split the dataset to training part and validation part**\n",
    "* **24000 training sentence, 6000 validation sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices = np.random.permutation(data_len)\n",
    "\n",
    "train_count = int(np.floor(data_len * 0.8))\n",
    "train_indices = rand_indices[0:train_count]\n",
    "val_indices = rand_indices[train_count:data_len]\n",
    "\n",
    "input_texts_train = input_texts[train_indices]\n",
    "target_texts_train = np.asarray(target_texts)[train_indices]\n",
    "\n",
    "encoder_input_train = encoder_input_data[train_indices]\n",
    "decoder_input_train = decoder_input_data[train_indices]\n",
    "decoder_target_train = decoder_target_data[train_indices]\n",
    "\n",
    "input_texts_val = input_texts[val_indices]\n",
    "target_texts_val = np.asarray(target_texts)[val_indices]\n",
    "encoder_input_val = encoder_input_data[val_indices]\n",
    "decoder_input_val = decoder_input_data[val_indices]\n",
    "decoder_target_val = decoder_target_data[val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_inputs (InputLayer)  (None, None, 28)          0         \n",
      "_________________________________________________________________\n",
      "encoder_lstm (GRU)           [(None, 256), (None, 256) 218880    \n",
      "=================================================================\n",
      "Total params: 218,880\n",
      "Trainable params: 218,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, GRU\n",
    "from keras.models import Model\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "# set the LSTM layer\n",
    "encoder_gru = GRU(latent_dim, return_state=True, name='encoder_lstm')\n",
    "_, state_h = encoder_gru(encoder_inputs)\n",
    "\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[state_h],\n",
    "                      name='encoder')\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               (None, None, 256)    220416      decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     7710        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 228,126\n",
      "Trainable params: 228,126\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, Dense, GRU\n",
    "from keras.models import Model\n",
    "\n",
    "# inputs of the decoder network\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "decoder_input_h = Input(shape=(latent_dim,), name='decoder_input_h')\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_gru = GRU(latent_dim, return_sequences=True, name='decoder_gru')\n",
    "decoder_outputs = decoder_gru(decoder_inputs, initial_state=decoder_input_h)\n",
    "\n",
    "\n",
    "# set the dense layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_inputs,decoder_input_h],\n",
    "                      outputs=[decoder_outputs], name='decoder')\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, 256)          218880      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               (None, None, 256)    220416      decoder_input_x[0][0]            \n",
      "                                                                 encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     7710        decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 447,006\n",
      "Trainable params: 447,006\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states = encoder_model([encoder_input_x])\n",
    "decoder_gru_output = decoder_gru(decoder_input_x, initial_state=encoder_final_states)\n",
    "decoder_pred = decoder_dense(decoder_gru_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "24000/24000 [==============================] - 27s 1ms/step - loss: 2.1883 - val_loss: 1.8845\n",
      "Epoch 2/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 1.7561 - val_loss: 1.6381\n",
      "Epoch 3/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.5613 - val_loss: 1.4910\n",
      "Epoch 4/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 1.4377 - val_loss: 1.4107\n",
      "Epoch 5/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 1.3608 - val_loss: 1.3358\n",
      "Epoch 6/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.2941 - val_loss: 1.2814\n",
      "Epoch 7/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.2430 - val_loss: 1.2420\n",
      "Epoch 8/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.2019 - val_loss: 1.2182\n",
      "Epoch 9/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.1685 - val_loss: 1.1865\n",
      "Epoch 10/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.1400 - val_loss: 1.1725\n",
      "Epoch 11/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.1153 - val_loss: 1.1505\n",
      "Epoch 12/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0934 - val_loss: 1.1374\n",
      "Epoch 13/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0745 - val_loss: 1.1309\n",
      "Epoch 14/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0572 - val_loss: 1.1185\n",
      "Epoch 15/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0419 - val_loss: 1.1044\n",
      "Epoch 16/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0275 - val_loss: 1.1030\n",
      "Epoch 17/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0143 - val_loss: 1.0919\n",
      "Epoch 18/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 1.0017 - val_loss: 1.0871\n",
      "Epoch 19/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9902 - val_loss: 1.0837\n",
      "Epoch 20/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9790 - val_loss: 1.0840\n",
      "Epoch 21/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9688 - val_loss: 1.0782\n",
      "Epoch 22/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9584 - val_loss: 1.0868\n",
      "Epoch 23/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9491 - val_loss: 1.0761\n",
      "Epoch 24/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9393 - val_loss: 1.0769\n",
      "Epoch 25/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9305 - val_loss: 1.0721\n",
      "Epoch 26/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9217 - val_loss: 1.0773\n",
      "Epoch 27/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9131 - val_loss: 1.0772\n",
      "Epoch 28/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.9047 - val_loss: 1.0944\n",
      "Epoch 29/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8967 - val_loss: 1.0838\n",
      "Epoch 30/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8884 - val_loss: 1.0885\n",
      "Epoch 31/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8805 - val_loss: 1.0871\n",
      "Epoch 32/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8730 - val_loss: 1.0914\n",
      "Epoch 33/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8656 - val_loss: 1.1020\n",
      "Epoch 34/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8579 - val_loss: 1.1015\n",
      "Epoch 35/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8502 - val_loss: 1.0999\n",
      "Epoch 36/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8429 - val_loss: 1.1090\n",
      "Epoch 37/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8357 - val_loss: 1.1303\n",
      "Epoch 38/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8283 - val_loss: 1.1203\n",
      "Epoch 39/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8212 - val_loss: 1.1504\n",
      "Epoch 40/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8137 - val_loss: 1.1475\n",
      "Epoch 41/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.8067 - val_loss: 1.1384\n",
      "Epoch 42/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.7995 - val_loss: 1.1694\n",
      "Epoch 43/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.7921 - val_loss: 1.1555\n",
      "Epoch 44/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 0.7854 - val_loss: 1.1639\n",
      "Epoch 45/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 0.7782 - val_loss: 1.2102\n",
      "Epoch 46/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.7715 - val_loss: 1.1783\n",
      "Epoch 47/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.7648 - val_loss: 1.1884\n",
      "Epoch 48/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 0.7587 - val_loss: 1.1961\n",
      "Epoch 49/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.7518 - val_loss: 1.2031\n",
      "Epoch 50/50\n",
      "24000/24000 [==============================] - 25s 1ms/step - loss: 0.7458 - val_loss: 1.2076\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "history = model.fit([encoder_input_train, decoder_input_train],  # training data\n",
    "                      decoder_target_train,                       # labels (left shift of the target sequences)\n",
    "                      batch_size=64, epochs=50, \n",
    "                      validation_data= ([encoder_input_val, decoder_input_val],decoder_target_val))\n",
    "\n",
    "model.save('seq2seq_gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
