{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS584 Homework 5: Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq: SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* English to French"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparationÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from unicodedata import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load_doc: loading file \n",
    "to_line: cutting the the whole file to line by line\n",
    "clean_data: remove the symble, url, or other irrevalent information \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def to_line(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return lines\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('utf-8', 'ignore')\n",
    "        #print(line)\n",
    "        line = line.decode('UTF-8')\n",
    "            \n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "            \n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "            \n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "            \n",
    "         # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        #print(line)\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "            \n",
    "        # store as string\n",
    "        cleaned.append(' '.join(line))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentencens match with French sentences \n",
      "\n",
      "English sentence: 2007723 \n",
      "\n",
      "French sentence: 2007723 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the first 30000 sentences to contruct dataset\n",
    "data_len = 30000\n",
    "\n",
    "en = load_doc('europarl-v7.fr-en.en')\n",
    "en_lines = to_line(en)\n",
    "fr = load_doc('europarl-v7.fr-en.fr')\n",
    "fr_lines = to_line(fr)\n",
    "\n",
    "if len(en_lines) == len(fr_lines):\n",
    "    print('English sentencens match with French sentences \\n')\n",
    "    print('English sentence:', len(en_lines), '\\n')\n",
    "    print('French sentence:', len(fr_lines), '\\n')\n",
    "else :\n",
    "    print('English sentencens does not match with French sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning english part and french part \n",
    "clean_en = clean_data(en_lines)[0:data_len]\n",
    "clean_fr = clean_data(fr_lines)[0:data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i should also like to make a few comments firstly mr berend regarding the assessment you have made of this sixth periodic report\n",
      "je voudrais a mon tour faire quelques observations dabord sur le jugement que vous portez monsieur le rapporteur sur ce sixieme rapport periodique\n"
     ]
    }
   ],
   "source": [
    "clean_en = np.array(clean_en)\n",
    "clean_fr = np.array(clean_fr)\n",
    "\n",
    "# A showcase \n",
    "print(clean_en[700])\n",
    "print(clean_fr[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (30000,)\n",
      "Length of target_texts: (30000,)\n",
      "max length of input  sentences: 32\n",
      "max length of target sentences: 34\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_en\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_fr]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))\n",
    "\n",
    "#This dataset includes lots of long sentence\n",
    "#But, if we set max length with a large number, CPU cannot handle that, so we set max_encode is 32\n",
    "#Becuase we add '\\t' and '\\n' to target, so the max_decode is 34\n",
    "max_encoder_seq_length = 32 \n",
    "max_decoder_seq_length = 34\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text to Sequence\n",
    "* One-hot embedding the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (30000, 32)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (30000, 34)\n",
      "shape of target_token_index: 29\n"
     ]
    }
   ],
   "source": [
    "def text2sequences(max_len, lines):\n",
    "    tokenizer = Tokenizer(char_level=True, filters='')\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    seqs = tokenizer.texts_to_sequences(lines)\n",
    "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "    return seqs_pad, tokenizer.word_index\n",
    "\n",
    "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, \n",
    "                                                      input_texts)\n",
    "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, \n",
    "                                                       target_texts)\n",
    "\n",
    "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "print('shape of target_token_index: ' + str(len(target_token_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_token_index) +1\n",
    "num_decoder_tokens = len(target_token_index) +1\n",
    "\n",
    "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
    "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(sequences, max_len, vocab_size):\n",
    "    n = len(sequences)\n",
    "    data = np.zeros((n, max_len, vocab_size))\n",
    "    for i in range(n):\n",
    "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 32, 28)\n",
      "(30000, 34, 30)\n",
      "(30000, 34, 30)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
    "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "decoder_target_seq = np.zeros(decoder_input_seq.shape)\n",
    "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "decoder_target_data = onehot_encode(decoder_target_seq, \n",
    "                                    max_decoder_seq_length, \n",
    "                                    num_decoder_tokens)\n",
    "\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Split the dataset to training part and validation part**\n",
    "* **24000 training sentence, 6000 validation sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indices = np.random.permutation(data_len)\n",
    "\n",
    "train_count = int(np.floor(data_len * 0.8))\n",
    "train_indices = rand_indices[0:train_count]\n",
    "val_indices = rand_indices[train_count:data_len]\n",
    "\n",
    "input_texts_train = input_texts[train_indices]\n",
    "target_texts_train = np.asarray(target_texts)[train_indices]\n",
    "\n",
    "encoder_input_train = encoder_input_data[train_indices]\n",
    "decoder_input_train = decoder_input_data[train_indices]\n",
    "decoder_target_train = decoder_target_data[train_indices]\n",
    "\n",
    "input_texts_val = input_texts[val_indices]\n",
    "target_texts_val = np.asarray(target_texts)[val_indices]\n",
    "encoder_input_val = encoder_input_data[val_indices]\n",
    "decoder_input_val = decoder_input_data[val_indices]\n",
    "decoder_target_val = decoder_target_data[val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_inputs (InputLayer)  (None, None, 28)          0         \n",
      "_________________________________________________________________\n",
      "encoder_rnn (SimpleRNN)      [(None, 256), (None, 256) 72960     \n",
      "=================================================================\n",
      "Total params: 72,960\n",
      "Trainable params: 72,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, SimpleRNN\n",
    "from keras.models import Model\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "# inputs of the encoder network\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), \n",
    "                       name='encoder_inputs')\n",
    "\n",
    "# set the LSTM layer\n",
    "encoder_rnn = SimpleRNN(latent_dim, return_state=True, name='encoder_rnn')\n",
    "_, state_h = encoder_rnn(encoder_inputs)\n",
    "\n",
    "\n",
    "# build the encoder network model\n",
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[state_h],\n",
    "                      name='encoder')\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_rnn (SimpleRNN)         (None, None, 256)    73472       decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     7710        decoder_rnn[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 81,182\n",
      "Trainable params: 81,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "from keras.models import Model\n",
    "\n",
    "# inputs of the decoder network\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "decoder_input_h = Input(shape=(latent_dim,), name='decoder_input_h')\n",
    "\n",
    "# set the LSTM layer\n",
    "decoder_rnn = SimpleRNN(latent_dim, return_sequences=True, name='decoder_rnn')\n",
    "decoder_outputs = decoder_rnn(decoder_inputs, initial_state=decoder_input_h)\n",
    "\n",
    "\n",
    "# set the dense layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# build the decoder network model\n",
    "decoder_model = Model(inputs=[decoder_inputs,decoder_input_h],\n",
    "                      outputs=[decoder_outputs], name='decoder')\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, 256)          72960       encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_rnn (SimpleRNN)         (None, None, 256)    73472       decoder_input_x[0][0]            \n",
      "                                                                 encoder[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     7710        decoder_rnn[3][0]                \n",
      "==================================================================================================\n",
      "Total params: 154,142\n",
      "Trainable params: 154,142\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layers\n",
    "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
    "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "# connect encoder to decoder\n",
    "encoder_final_states = encoder_model([encoder_input_x])\n",
    "decoder_rnn_output = decoder_rnn(decoder_input_x, initial_state=encoder_final_states)\n",
    "decoder_pred = decoder_dense(decoder_rnn_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "              outputs=decoder_pred, \n",
    "              name='model_training')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "24000/24000 [==============================] - 15s 620us/step - loss: 2.1336 - val_loss: 1.8739\n",
      "Epoch 2/50\n",
      "24000/24000 [==============================] - 14s 601us/step - loss: 1.8217 - val_loss: 1.7760\n",
      "Epoch 3/50\n",
      "24000/24000 [==============================] - 14s 602us/step - loss: 1.7306 - val_loss: 1.6939\n",
      "Epoch 4/50\n",
      "24000/24000 [==============================] - 14s 598us/step - loss: 1.6382 - val_loss: 1.6108\n",
      "Epoch 5/50\n",
      "24000/24000 [==============================] - 14s 577us/step - loss: 1.5575 - val_loss: 1.5380\n",
      "Epoch 6/50\n",
      "24000/24000 [==============================] - 15s 610us/step - loss: 1.4929 - val_loss: 1.4965\n",
      "Epoch 7/50\n",
      "24000/24000 [==============================] - 14s 601us/step - loss: 1.4422 - val_loss: 1.4660\n",
      "Epoch 8/50\n",
      "24000/24000 [==============================] - 14s 597us/step - loss: 1.4009 - val_loss: 1.4135\n",
      "Epoch 9/50\n",
      "24000/24000 [==============================] - 15s 605us/step - loss: 1.3662 - val_loss: 1.3893\n",
      "Epoch 10/50\n",
      "24000/24000 [==============================] - 15s 608us/step - loss: 1.3370 - val_loss: 1.3652\n",
      "Epoch 11/50\n",
      "24000/24000 [==============================] - 14s 600us/step - loss: 1.3121 - val_loss: 1.3356\n",
      "Epoch 12/50\n",
      "24000/24000 [==============================] - 15s 609us/step - loss: 1.2904 - val_loss: 1.3265\n",
      "Epoch 13/50\n",
      "24000/24000 [==============================] - 14s 603us/step - loss: 1.2708 - val_loss: 1.3129\n",
      "Epoch 14/50\n",
      "24000/24000 [==============================] - 15s 612us/step - loss: 1.2534 - val_loss: 1.2911\n",
      "Epoch 15/50\n",
      "24000/24000 [==============================] - 14s 596us/step - loss: 1.2373 - val_loss: 1.2896\n",
      "Epoch 16/50\n",
      "24000/24000 [==============================] - 15s 610us/step - loss: 1.2249 - val_loss: 1.2754\n",
      "Epoch 17/50\n",
      "24000/24000 [==============================] - 14s 601us/step - loss: 1.2121 - val_loss: 1.2603\n",
      "Epoch 18/50\n",
      "24000/24000 [==============================] - 15s 606us/step - loss: 1.2009 - val_loss: 1.2624\n",
      "Epoch 19/50\n",
      "24000/24000 [==============================] - 15s 609us/step - loss: 1.1909 - val_loss: 1.2504\n",
      "Epoch 20/50\n",
      "24000/24000 [==============================] - 14s 599us/step - loss: 1.1908 - val_loss: 1.2438\n",
      "Epoch 21/50\n",
      "24000/24000 [==============================] - 15s 608us/step - loss: 1.1729 - val_loss: 1.2348\n",
      "Epoch 22/50\n",
      "24000/24000 [==============================] - 15s 616us/step - loss: 1.1647 - val_loss: 1.2358\n",
      "Epoch 23/50\n",
      "24000/24000 [==============================] - 14s 604us/step - loss: 1.1561 - val_loss: 1.2323\n",
      "Epoch 24/50\n",
      "24000/24000 [==============================] - 15s 606us/step - loss: 1.1494 - val_loss: 1.2232\n",
      "Epoch 25/50\n",
      "24000/24000 [==============================] - 14s 601us/step - loss: 1.1430 - val_loss: 1.2194\n",
      "Epoch 26/50\n",
      "24000/24000 [==============================] - 14s 601us/step - loss: 1.1368 - val_loss: 1.2129\n",
      "Epoch 27/50\n",
      "24000/24000 [==============================] - 15s 612us/step - loss: 1.1307 - val_loss: 1.2122\n",
      "Epoch 28/50\n",
      "24000/24000 [==============================] - 14s 604us/step - loss: 1.1254 - val_loss: 1.2122\n",
      "Epoch 29/50\n",
      "24000/24000 [==============================] - 15s 615us/step - loss: 1.1688 - val_loss: 1.2304\n",
      "Epoch 30/50\n",
      "24000/24000 [==============================] - 15s 606us/step - loss: 1.1295 - val_loss: 1.2001\n",
      "Epoch 31/50\n",
      "24000/24000 [==============================] - 15s 607us/step - loss: 1.1146 - val_loss: 1.1968\n",
      "Epoch 32/50\n",
      "24000/24000 [==============================] - 15s 608us/step - loss: 1.1085 - val_loss: 1.1930\n",
      "Epoch 33/50\n",
      "24000/24000 [==============================] - 15s 606us/step - loss: 1.1035 - val_loss: 1.1936\n",
      "Epoch 34/50\n",
      "24000/24000 [==============================] - 15s 605us/step - loss: 1.0996 - val_loss: 1.1894\n",
      "Epoch 35/50\n",
      "24000/24000 [==============================] - 15s 612us/step - loss: 1.0953 - val_loss: 1.1951\n",
      "Epoch 36/50\n",
      "24000/24000 [==============================] - 14s 588us/step - loss: 1.0919 - val_loss: 1.1921\n",
      "Epoch 37/50\n",
      "24000/24000 [==============================] - 14s 596us/step - loss: 1.0881 - val_loss: 1.1893\n",
      "Epoch 38/50\n",
      "24000/24000 [==============================] - 14s 595us/step - loss: 1.0847 - val_loss: 1.1884\n",
      "Epoch 39/50\n",
      "24000/24000 [==============================] - 14s 595us/step - loss: 1.0821 - val_loss: 1.1838\n",
      "Epoch 40/50\n",
      "24000/24000 [==============================] - 14s 604us/step - loss: 1.0786 - val_loss: 1.1872\n",
      "Epoch 41/50\n",
      "24000/24000 [==============================] - 14s 602us/step - loss: 1.0768 - val_loss: 1.1867\n",
      "Epoch 42/50\n",
      "24000/24000 [==============================] - 15s 612us/step - loss: 1.0728 - val_loss: 1.1835\n",
      "Epoch 43/50\n",
      "24000/24000 [==============================] - 15s 610us/step - loss: 1.0805 - val_loss: 1.1861\n",
      "Epoch 44/50\n",
      "24000/24000 [==============================] - 15s 608us/step - loss: 1.0698 - val_loss: 1.1837\n",
      "Epoch 45/50\n",
      "24000/24000 [==============================] - 15s 607us/step - loss: 1.0654 - val_loss: 1.1870\n",
      "Epoch 46/50\n",
      "24000/24000 [==============================] - 15s 611us/step - loss: 1.0627 - val_loss: 1.1800\n",
      "Epoch 47/50\n",
      "24000/24000 [==============================] - 15s 606us/step - loss: 1.0601 - val_loss: 1.1860\n",
      "Epoch 48/50\n",
      "24000/24000 [==============================] - 15s 617us/step - loss: 1.0580 - val_loss: 1.1765\n",
      "Epoch 49/50\n",
      "24000/24000 [==============================] - 15s 608us/step - loss: 1.0555 - val_loss: 1.1849\n",
      "Epoch 50/50\n",
      "24000/24000 [==============================] - 15s 615us/step - loss: 1.0534 - val_loss: 1.1822\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "history = model.fit([encoder_input_train, decoder_input_train],  # training data\n",
    "                      decoder_target_train,                       # labels (left shift of the target sequences)\n",
    "                      batch_size=64, epochs=50, \n",
    "                      validation_data= ([encoder_input_val, decoder_input_val],decoder_target_val))\n",
    "\n",
    "model.save('seq2seq_gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
