{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HM1: Text Classification\n",
    "\n",
    "### Name: [Yupeng Cao]\n",
    "### ID: [10454637]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1 Preprocess data and Construct examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = 'data/28054-0.txt' #Define File Path\n",
    "file_2 = 'data/pg31100.txt'\n",
    "file_3 = 'data/pg1661.txt'\n",
    "\n",
    "#Define a function to process raw data\n",
    "#Inputs:\n",
    "#       filepath: the location where you put data.\n",
    "def txt2paragraph(filepath):\n",
    "    \n",
    "    url_reg  = r'[a-z]*[:.]+\\S+' #Regular Expression for remove url\n",
    "    punctuation = '.!,;:?\"\"\\'''*#@â€œ'#Regular Expression for remove symbol\n",
    "    \n",
    "    #Load file\n",
    "    with open(filepath, \"r\", encoding=\"UTF-8\") as file:\n",
    "        lines = file.read()\n",
    "    new = lines.split(\"\\n\\n\") #Split file into paragraphy\n",
    "    \n",
    "    #Preprocess for each paragraphy\n",
    "    for para in range(len(new)):\n",
    "        new[para] = new[para].lower().replace('\\n', '') #remove \\n\n",
    "        new[para] = re.sub(url_reg, '', new[para]) #remove url\n",
    "        new[para] = new[para].strip() #remove blank space\n",
    "        new[para] = re.sub(r'\\d+', '', new[para]) #remove digit\n",
    "        new[para] = re.sub(r'[{}]+'.format(punctuation),'',new[para]) #remove puncutation and symbol\n",
    "\n",
    "    #Double check \n",
    "    while '' in new:\n",
    "        new.remove('')\n",
    "    #Return the results\n",
    "    return new\n",
    "\n",
    "#Remove the irrevelant information at the begin and end of the E-Book.\n",
    "data_1 = txt2paragraph(file_1)[19:5959]\n",
    "data_2 = txt2paragraph(file_2)[29:11047]\n",
    "data_3 = txt2paragraph(file_3)[14:1986]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5940 text data belongs to Fyodor Dostoyevsky\n",
      "11018 text data belongs to Jane Auste\n",
      "1972 text data belongs to Arthur Conan Doyle\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#Construct the dataset by using three sub-data from last step:\n",
    "#    1. Construct the dataframe for each part by using Pandas.DataFrame\n",
    "#    2. Connect the each part to form the whole dataset.\n",
    "\n",
    "\n",
    "dataset_part1 = pd.DataFrame()\n",
    "dataset_part1['text'] = data_1\n",
    "#dataset_part1['label'] = 0\n",
    "dataset_part1['label'] = 'Fyodor Dostoyevsky'\n",
    "\n",
    "dataset_part2 = pd.DataFrame()\n",
    "dataset_part2['text'] = data_2\n",
    "#dataset_part2['label'] = 1\n",
    "dataset_part2['label'] = 'Jane Auste'\n",
    "\n",
    "dataset_part3 = pd.DataFrame()\n",
    "dataset_part3['text'] = data_3\n",
    "#dataset_part3['label'] = 2\n",
    "dataset_part3['label'] = 'Arthur Conan Doyle'\n",
    "\n",
    "text_data = [dataset_part1, dataset_part2,dataset_part3]\n",
    "dataset = pd.concat(text_data, axis = 0, ignore_index=True)\n",
    "dataset = shuffle(dataset) #We shuffle the dataset \n",
    "\n",
    "#print(dataset) # You can view the final DataFrame \n",
    "print(str(len(data_1)) + ' text data belongs to Fyodor Dostoyevsky')\n",
    "print(str(len(data_2)) + ' text data belongs to Jane Auste')\n",
    "print(str(len(data_3)) + ' text data belongs to Arthur Conan Doyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "dataset['encode_label'] = encoder.fit_transform(dataset['label'].values)\n",
    "\n",
    "#Valdation part: 20%\n",
    "#Because we shuffle the dataset at the last step, therefore, we set random_state is 1.\n",
    "train_x, val_x, train_y, val_y = model_selection.train_test_split(dataset['text'].values, dataset['encode_label'].values,\n",
    "                                                                  test_size=0.2, random_state=1)\n",
    "train_y = train_y.reshape(-1,1)\n",
    "val_y = val_y.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Feature Extraction: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stop words\n",
    "# min_df = 50:\n",
    "#      If the frequency of the word lower than 50 times, it wll be ignored\n",
    "stop_w = nltk.corpus.stopwords.words('english') \n",
    "tfidf_vect = TfidfVectorizer(stop_words = stop_w, min_df=50)\n",
    "\n",
    "#Calculate TF-IDF\n",
    "tfidf_vect.fit(dataset['text'])\n",
    "xtrain = tfidf_vect.transform(train_x)\n",
    "xval = tfidf_vect.transform(val_x)\n",
    "xtrain = xtrain.toarray()\n",
    "xval = xval.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=1}^{K}y_{ik}log(\\frac{exp f_{k}}{\\sum_{K}^{c=1}expf_{c}}) + \\lambda \\sum_{j=1}^{d}w_{kj}^2 $$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The gradient of J with respect to wk is:**<br>\n",
    "**Let $Z = \\omega _{k}^Tx$**. Then, applying chain rule to **J**: <br>\n",
    "$$\\frac{\\partial J}{\\partial \\omega } = \\frac{\\partial Z}{\\partial \\omega } \\frac{\\partial J}{\\partial Z } + 2\\lambda \\sum \\omega _{k}$$<br>\n",
    "$$\\frac{\\partial J}{\\partial \\omega } = x^T(\\frac{exp(\\omega_{i})}{\\sum_{k} exp(\\omega _{k}) }) + 2\\lambda \\sum_{k}\\omega _{k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define One-Hot encoding function and softmax function\n",
    "# Two function will be used in mini-batch SGD and SGD\n",
    "\n",
    "#Input:\n",
    "#      y: label\n",
    "def OneHot(y, num_class=3):\n",
    "    results = np.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y):\n",
    "        results[i, label.astype('int')] = 1\n",
    "    return results\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Mini-Batch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the objective function and gradient function\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix, n is batch size at here\n",
    "#     w: d-by-3 matrix\n",
    "#     y: n-by-3 matrix, n is batch size at here\n",
    "def mb_sgd_objective_gradient(w,x,y,lam):\n",
    "    \n",
    "    n,d = x.shape\n",
    "    y_mat = OneHot(y)\n",
    "    xw = np.dot(x,w)\n",
    "    exp_xw = softmax(xw)\n",
    "    \n",
    "    obj = -np.mean(np.sum(y_mat * np.log(exp_xw),axis=1)) + lam*np.sum(w*w)\n",
    "    \n",
    "    grad = -(1/n) * np.dot(x.T,(y_mat - exp_xw)) + lam * w\n",
    "    \n",
    "    return obj, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the mini-batch SGD\n",
    "#Input:\n",
    "#      x: whole dataset\n",
    "#      y: whole labels\n",
    "#      lam: the regularization parameter\n",
    "#      batch_size: 4, 8, 16, 32, 64, 128, 256...\n",
    "#      stepsize: learning rate\n",
    "#      max_epochs: 100\n",
    "#      w: we initialize w metrix in function.\n",
    "def mb_gradient_descent(x,y,lam,batch_size,stepsize,max_epochs,w=None):\n",
    "\n",
    "    n,d = x.shape\n",
    "    num_batch = int(np.ceil(n/batch_size))\n",
    "    obj_vals = np.zeros(max_epochs)\n",
    "    \n",
    "    #initialize w metrix\n",
    "    # w: d-by-3\n",
    "    if w is None:\n",
    "        w = np.zeros((d,3))\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        rand_index = np.random.permutation(n)\n",
    "        x_rand = x[rand_index,:]\n",
    "        y_rand =y[rand_index]\n",
    "        obj_val = 0\n",
    "        \n",
    "        for i in range(1,num_batch+1):\n",
    "            mini_x = x_rand[(i-1)*batch_size:i*batch_size, :]\n",
    "            mini_y = y_rand[(i-1)*batch_size:i*batch_size]\n",
    "      \n",
    "            obj, g = mb_sgd_objective_gradient(w,mini_x,mini_y,lam)\n",
    "            obj_val += obj\n",
    "            w -= stepsize * g\n",
    "    \n",
    "        obj_val /= num_batch\n",
    "        obj_vals[epoch] = obj_val\n",
    "        print('Objective value at ' + str(epoch) + ' is ' + str(obj_val))\n",
    "    \n",
    "    return w, obj_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at 0 is 4.841205388760497\n",
      "Objective value at 1 is 4.839036827618762\n",
      "Objective value at 2 is 4.836956097281766\n",
      "Objective value at 3 is 4.834877449700911\n",
      "Objective value at 4 is 4.832813646356651\n",
      "Objective value at 5 is 4.830810268514768\n",
      "Objective value at 6 is 4.8288743407883965\n",
      "Objective value at 7 is 4.826965364572173\n",
      "Objective value at 8 is 4.825058529942545\n",
      "Objective value at 9 is 4.823269236978596\n",
      "Objective value at 10 is 4.821434146703816\n",
      "Objective value at 11 is 4.819587591165848\n",
      "Objective value at 12 is 4.817854764025717\n",
      "Objective value at 13 is 4.81606054663267\n",
      "Objective value at 14 is 4.814394410266627\n",
      "Objective value at 15 is 4.812734843403792\n",
      "Objective value at 16 is 4.81117635379941\n",
      "Objective value at 17 is 4.809533530783282\n",
      "Objective value at 18 is 4.807950144622446\n",
      "Objective value at 19 is 4.806606748812173\n",
      "Objective value at 20 is 4.804982128173232\n",
      "Objective value at 21 is 4.803620129675079\n",
      "Objective value at 22 is 4.8022680485548745\n",
      "Objective value at 23 is 4.80073179613212\n",
      "Objective value at 24 is 4.799659185707211\n",
      "Objective value at 25 is 4.7984201736434695\n",
      "Objective value at 26 is 4.797051981891225\n",
      "Objective value at 27 is 4.795963329357881\n",
      "Objective value at 28 is 4.794724881547384\n",
      "Objective value at 29 is 4.793790957883171\n",
      "Objective value at 30 is 4.792529135651732\n",
      "Objective value at 31 is 4.791397792777049\n",
      "Objective value at 32 is 4.790626264557536\n",
      "Objective value at 33 is 4.78981386335317\n",
      "Objective value at 34 is 4.78856926193647\n",
      "Objective value at 35 is 4.787469647309851\n",
      "Objective value at 36 is 4.786924455691139\n",
      "Objective value at 37 is 4.786134552271406\n",
      "Objective value at 38 is 4.785324066393044\n",
      "Objective value at 39 is 4.784790939270087\n",
      "Objective value at 40 is 4.783690544154268\n",
      "Objective value at 41 is 4.782998015468086\n",
      "Objective value at 42 is 4.782529324516466\n",
      "Objective value at 43 is 4.7819837351104155\n",
      "Objective value at 44 is 4.781294412320008\n",
      "Objective value at 45 is 4.780865822007493\n",
      "Objective value at 46 is 4.780491665198042\n",
      "Objective value at 47 is 4.779936104365399\n",
      "Objective value at 48 is 4.779654504445469\n",
      "Objective value at 49 is 4.779395325812288\n",
      "Objective value at 50 is 4.779185818335921\n",
      "Objective value at 51 is 4.7791839607286475\n",
      "Objective value at 52 is 4.77808975330112\n",
      "Objective value at 53 is 4.778425114489395\n",
      "Objective value at 54 is 4.778560098925478\n",
      "Objective value at 55 is 4.778032373185405\n",
      "Objective value at 56 is 4.778672867552995\n",
      "Objective value at 57 is 4.777781557862841\n",
      "Objective value at 58 is 4.778239247351852\n",
      "Objective value at 59 is 4.778892134715349\n",
      "Objective value at 60 is 4.778902171143288\n",
      "Objective value at 61 is 4.778210134182304\n",
      "Objective value at 62 is 4.7787615515040285\n",
      "Objective value at 63 is 4.778779656401614\n",
      "Objective value at 64 is 4.779301149717647\n",
      "Objective value at 65 is 4.779986097750205\n",
      "Objective value at 66 is 4.779508401974601\n",
      "Objective value at 67 is 4.780520496326484\n",
      "Objective value at 68 is 4.781261643883171\n",
      "Objective value at 69 is 4.7815232280180835\n",
      "Objective value at 70 is 4.782346259437226\n",
      "Objective value at 71 is 4.782154597486061\n",
      "Objective value at 72 is 4.7832097129687465\n",
      "Objective value at 73 is 4.783909555663362\n",
      "Objective value at 74 is 4.784617365547704\n",
      "Objective value at 75 is 4.784973443869255\n",
      "Objective value at 76 is 4.786600008192114\n",
      "Objective value at 77 is 4.787117459349619\n",
      "Objective value at 78 is 4.788622839228884\n",
      "Objective value at 79 is 4.789414296718784\n",
      "Objective value at 80 is 4.790484936658053\n",
      "Objective value at 81 is 4.790802128645897\n",
      "Objective value at 82 is 4.792120322267295\n",
      "Objective value at 83 is 4.793198517622823\n",
      "Objective value at 84 is 4.794422352429992\n",
      "Objective value at 85 is 4.796531729136205\n",
      "Objective value at 86 is 4.797996456559905\n",
      "Objective value at 87 is 4.7986721649768835\n",
      "Objective value at 88 is 4.800781359261792\n",
      "Objective value at 89 is 4.8015444053864575\n",
      "Objective value at 90 is 4.802913765810421\n",
      "Objective value at 91 is 4.803645056045738\n",
      "Objective value at 92 is 4.805600574139491\n",
      "Objective value at 93 is 4.807920583620878\n",
      "Objective value at 94 is 4.810140730758307\n",
      "Objective value at 95 is 4.8106906729418135\n",
      "Objective value at 96 is 4.81270025240945\n",
      "Objective value at 97 is 4.814360989695175\n",
      "Objective value at 98 is 4.816795945203775\n",
      "Objective value at 99 is 4.817650783768071\n"
     ]
    }
   ],
   "source": [
    "w, obj_vals = mb_gradient_descent(xtrain, train_y, 1E-6, 128, stepsize = 0.01, max_epochs = 100, w=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b98b6ab00>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_1 = plt.figure(figsize=(6, 4))\n",
    "x_range = range(len(obj_vals))\n",
    "plt.plot(x_range, obj_vals, '--b', label = 'Training loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_objective_gradient(w,x,y,lam):\n",
    "    \n",
    "    y_mat = OneHot(y)\n",
    "    xw = np.dot(x,w)\n",
    "    exp_xw = softmax(xw)\n",
    "    \n",
    "    obj = -np.mean(np.sum(y_mat * np.log(exp_xw),axis=1)) + lam*np.sum(w*w)\n",
    "    \n",
    "    grad = -np.dot(x.T,(y_mat - exp_xw)) + lam * w\n",
    "    \n",
    "    return obj, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x,y,lam,stepsize,max_epochs,w=None):\n",
    "    n,d = x.shape\n",
    "    obj_vals = np.zeros(max_epochs)\n",
    "    \n",
    "    if w is None:\n",
    "        w = np.zeros((d,3))\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        rand_index = np.random.permutation(n)\n",
    "        x_rand = x[rand_index,:]\n",
    "        y_rand = y[rand_index]\n",
    "        obj_val = 0\n",
    "        \n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :].reshape(1, -1)\n",
    "            yi = y_rand[i]\n",
    "      \n",
    "            obj, g = sgd_objective_gradient(w,xi,yi,lam)\n",
    "            obj_val += obj\n",
    "            w -= stepsize * g\n",
    "        stepsize *= 0.9\n",
    "        obj_val /= n\n",
    "        obj_vals[epoch] = obj_val\n",
    "        print('Objective value at ' + str(epoch) + ' is ' + str(obj_val))\n",
    "    \n",
    "    return w, obj_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at 0 is 1.997216024105853e-06\n",
      "Objective value at 1 is 1.2981924469317569e-05\n",
      "Objective value at 2 is 3.211567839215851e-05\n",
      "Objective value at 3 is 5.681897069036438e-05\n",
      "Objective value at 4 is 8.515164484057553e-05\n",
      "Objective value at 5 is 0.00011556025864877883\n",
      "Objective value at 6 is 0.0001469415765894066\n",
      "Objective value at 7 is 0.00017840463445470146\n",
      "Objective value at 8 is 0.00020936078354660833\n",
      "Objective value at 9 is 0.00023924458513038615\n",
      "Objective value at 10 is 0.0002678292141217612\n",
      "Objective value at 11 is 0.00029509011720939835\n",
      "Objective value at 12 is 0.00032061613905034055\n",
      "Objective value at 13 is 0.0003445884248839607\n",
      "Objective value at 14 is 0.00036682352842519835\n",
      "Objective value at 15 is 0.00038747708748389985\n",
      "Objective value at 16 is 0.0004066191603988936\n",
      "Objective value at 17 is 0.00042414875924706865\n",
      "Objective value at 18 is 0.00044022626054758134\n",
      "Objective value at 19 is 0.00045497949057957967\n",
      "Objective value at 20 is 0.0004685072936788654\n",
      "Objective value at 21 is 0.0004808269128892614\n",
      "Objective value at 22 is 0.0004920354285133049\n",
      "Objective value at 23 is 0.0005022035973489076\n",
      "Objective value at 24 is 0.0005115273187919505\n",
      "Objective value at 25 is 0.0005199324350934364\n",
      "Objective value at 26 is 0.0005275540546460355\n",
      "Objective value at 27 is 0.0005344873507081106\n",
      "Objective value at 28 is 0.0005407721539431483\n",
      "Objective value at 29 is 0.0005464365000120878\n",
      "Objective value at 30 is 0.0005515522818327969\n",
      "Objective value at 31 is 0.0005561982549720226\n",
      "Objective value at 32 is 0.0005603962633747166\n",
      "Objective value at 33 is 0.0005641679342904441\n",
      "Objective value at 34 is 0.0005675946732902345\n",
      "Objective value at 35 is 0.0005706754164811487\n",
      "Objective value at 36 is 0.000573458836471314\n",
      "Objective value at 37 is 0.0005759715182870091\n",
      "Objective value at 38 is 0.0005782455691972528\n",
      "Objective value at 39 is 0.0005802804329361922\n",
      "Objective value at 40 is 0.0005821235230744356\n",
      "Objective value at 41 is 0.000583782075620054\n",
      "Objective value at 42 is 0.0005852809640213485\n",
      "Objective value at 43 is 0.0005866246386972774\n",
      "Objective value at 44 is 0.0005878371192078179\n",
      "Objective value at 45 is 0.0005889329282396093\n",
      "Objective value at 46 is 0.0005899159889558941\n",
      "Objective value at 47 is 0.000590805613212091\n",
      "Objective value at 48 is 0.000591605088084702\n",
      "Objective value at 49 is 0.0005923228815618641\n",
      "Objective value at 50 is 0.0005929716256373632\n",
      "Objective value at 51 is 0.0005935564130191403\n",
      "Objective value at 52 is 0.0005940805595112361\n",
      "Objective value at 53 is 0.0005945540477005377\n",
      "Objective value at 54 is 0.0005949792378371876\n",
      "Objective value at 55 is 0.0005953641001683238\n",
      "Objective value at 56 is 0.0005957087546879942\n",
      "Objective value at 57 is 0.0005960198292430267\n",
      "Objective value at 58 is 0.0005962997660446733\n",
      "Objective value at 59 is 0.0005965511765676065\n",
      "Objective value at 60 is 0.0005967781739246883\n",
      "Objective value at 61 is 0.0005969827062086694\n",
      "Objective value at 62 is 0.000597166174981917\n",
      "Objective value at 63 is 0.0005973315967336832\n",
      "Objective value at 64 is 0.0005974801890179477\n",
      "Objective value at 65 is 0.0005976142571183491\n",
      "Objective value at 66 is 0.0005977350319579315\n",
      "Objective value at 67 is 0.0005978436351718665\n",
      "Objective value at 68 is 0.0005979411513830607\n",
      "Objective value at 69 is 0.0005980291713867857\n",
      "Objective value at 70 is 0.0005981082034907736\n",
      "Objective value at 71 is 0.0005981795475313065\n",
      "Objective value at 72 is 0.000598243567649483\n",
      "Objective value at 73 is 0.0005983013397168322\n",
      "Objective value at 74 is 0.0005983532591243124\n",
      "Objective value at 75 is 0.0005984000940433607\n",
      "Objective value at 76 is 0.0005984421121576701\n",
      "Objective value at 77 is 0.0005984799958992876\n",
      "Objective value at 78 is 0.0005985140362649928\n",
      "Objective value at 79 is 0.0005985447497780159\n",
      "Objective value at 80 is 0.0005985723863242711\n",
      "Objective value at 81 is 0.0005985971998665354\n",
      "Objective value at 82 is 0.0005986196662928936\n",
      "Objective value at 83 is 0.0005986396957263021\n",
      "Objective value at 84 is 0.0005986578464091545\n",
      "Objective value at 85 is 0.0005986741522398802\n",
      "Objective value at 86 is 0.0005986887989538907\n",
      "Objective value at 87 is 0.0005987020580900806\n",
      "Objective value at 88 is 0.0005987139264137656\n",
      "Objective value at 89 is 0.0005987246265111398\n",
      "Objective value at 90 is 0.0005987342355508141\n",
      "Objective value at 91 is 0.0005987428927509624\n",
      "Objective value at 92 is 0.0005987507205145931\n",
      "Objective value at 93 is 0.0005987577395902881\n",
      "Objective value at 94 is 0.0005987640524671844\n",
      "Objective value at 95 is 0.000598769730844059\n",
      "Objective value at 96 is 0.0005987748433003785\n",
      "Objective value at 97 is 0.0005987794471332648\n",
      "Objective value at 98 is 0.0005987835976411437\n",
      "Objective value at 99 is 0.0005987873282657902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.17302712, -0.17171733, -0.0013098 ],\n",
       "        [-0.12924281, -0.12924281,  0.        ],\n",
       "        [-0.27087661, -0.2699903 , -0.00088631],\n",
       "        ...,\n",
       "        [-0.0963973 , -0.0902703 , -0.01048466],\n",
       "        [-0.160566  , -0.11055724, -0.08384786],\n",
       "        [-0.17175498,  0.        , -0.17175498]]),\n",
       " array([1.99721602e-06, 1.29819245e-05, 3.21156784e-05, 5.68189707e-05,\n",
       "        8.51516448e-05, 1.15560259e-04, 1.46941577e-04, 1.78404634e-04,\n",
       "        2.09360784e-04, 2.39244585e-04, 2.67829214e-04, 2.95090117e-04,\n",
       "        3.20616139e-04, 3.44588425e-04, 3.66823528e-04, 3.87477087e-04,\n",
       "        4.06619160e-04, 4.24148759e-04, 4.40226261e-04, 4.54979491e-04,\n",
       "        4.68507294e-04, 4.80826913e-04, 4.92035429e-04, 5.02203597e-04,\n",
       "        5.11527319e-04, 5.19932435e-04, 5.27554055e-04, 5.34487351e-04,\n",
       "        5.40772154e-04, 5.46436500e-04, 5.51552282e-04, 5.56198255e-04,\n",
       "        5.60396263e-04, 5.64167934e-04, 5.67594673e-04, 5.70675416e-04,\n",
       "        5.73458836e-04, 5.75971518e-04, 5.78245569e-04, 5.80280433e-04,\n",
       "        5.82123523e-04, 5.83782076e-04, 5.85280964e-04, 5.86624639e-04,\n",
       "        5.87837119e-04, 5.88932928e-04, 5.89915989e-04, 5.90805613e-04,\n",
       "        5.91605088e-04, 5.92322882e-04, 5.92971626e-04, 5.93556413e-04,\n",
       "        5.94080560e-04, 5.94554048e-04, 5.94979238e-04, 5.95364100e-04,\n",
       "        5.95708755e-04, 5.96019829e-04, 5.96299766e-04, 5.96551177e-04,\n",
       "        5.96778174e-04, 5.96982706e-04, 5.97166175e-04, 5.97331597e-04,\n",
       "        5.97480189e-04, 5.97614257e-04, 5.97735032e-04, 5.97843635e-04,\n",
       "        5.97941151e-04, 5.98029171e-04, 5.98108203e-04, 5.98179548e-04,\n",
       "        5.98243568e-04, 5.98301340e-04, 5.98353259e-04, 5.98400094e-04,\n",
       "        5.98442112e-04, 5.98479996e-04, 5.98514036e-04, 5.98544750e-04,\n",
       "        5.98572386e-04, 5.98597200e-04, 5.98619666e-04, 5.98639696e-04,\n",
       "        5.98657846e-04, 5.98674152e-04, 5.98688799e-04, 5.98702058e-04,\n",
       "        5.98713926e-04, 5.98724627e-04, 5.98734236e-04, 5.98742893e-04,\n",
       "        5.98750721e-04, 5.98757740e-04, 5.98764052e-04, 5.98769731e-04,\n",
       "        5.98774843e-04, 5.98779447e-04, 5.98783598e-04, 5.98787328e-04]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd(xtrain, train_y, 1E-6, stepsize = 0.001 ,max_epochs = 100, w=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the loss value of SGD, it keeps a slight increase which means that optimization process doesn't convergence. Therefore, we didn't plot the loss curve for SGD. The error reason will be analyzed at the last part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Requirement:**<br>\n",
    "Tensorflow: pip install tensorflow<br>\n",
    "Keras: pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_y)\n",
    "test_labels = to_categorical(val_y)\n",
    "\n",
    "#Build the model\n",
    "#3-Layer MLP:\n",
    "#    1. The size of input layer is same with the dimension of single data sample\n",
    "#    2. Output: 256, 128, 3\n",
    "#    3. Use softmax as the activation function at last layer\n",
    "#    4. We choose rmsprop as optimizer\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(256, activation = 'relu', input_shape = (xtrain.shape[1],)))\n",
    "network.add(layers.Dense(128, activation = 'relu'))\n",
    "network.add(layers.Dense(3, activation = 'softmax'))\n",
    "network.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#models.summary() #You can use models.summary() to check the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12115 samples, validate on 3029 samples\n",
      "Epoch 1/30\n",
      "12115/12115 [==============================] - 1s 119us/step - loss: 0.4718 - accuracy: 0.8024 - val_loss: 0.3388 - val_accuracy: 0.8646\n",
      "Epoch 2/30\n",
      "12115/12115 [==============================] - 1s 113us/step - loss: 0.2829 - accuracy: 0.8771 - val_loss: 0.3136 - val_accuracy: 0.8603\n",
      "Epoch 3/30\n",
      "12115/12115 [==============================] - 1s 113us/step - loss: 0.2442 - accuracy: 0.8946 - val_loss: 0.3085 - val_accuracy: 0.8613\n",
      "Epoch 4/30\n",
      "12115/12115 [==============================] - 1s 115us/step - loss: 0.2207 - accuracy: 0.9058 - val_loss: 0.3278 - val_accuracy: 0.8683\n",
      "Epoch 5/30\n",
      "12115/12115 [==============================] - 1s 113us/step - loss: 0.2013 - accuracy: 0.9135 - val_loss: 0.3411 - val_accuracy: 0.8699\n",
      "Epoch 6/30\n",
      "12115/12115 [==============================] - 1s 114us/step - loss: 0.1835 - accuracy: 0.9207 - val_loss: 0.3497 - val_accuracy: 0.8699\n",
      "Epoch 7/30\n",
      "12115/12115 [==============================] - 1s 112us/step - loss: 0.1676 - accuracy: 0.9274 - val_loss: 0.3524 - val_accuracy: 0.8676\n",
      "Epoch 8/30\n",
      "12115/12115 [==============================] - 1s 116us/step - loss: 0.1535 - accuracy: 0.9341 - val_loss: 0.3924 - val_accuracy: 0.8726\n",
      "Epoch 9/30\n",
      "12115/12115 [==============================] - 2s 128us/step - loss: 0.1392 - accuracy: 0.9405 - val_loss: 0.4106 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "12115/12115 [==============================] - 2s 140us/step - loss: 0.1263 - accuracy: 0.9468 - val_loss: 0.4446 - val_accuracy: 0.8696\n",
      "Epoch 11/30\n",
      "12115/12115 [==============================] - 1s 121us/step - loss: 0.1149 - accuracy: 0.9516 - val_loss: 0.4760 - val_accuracy: 0.8676\n",
      "Epoch 12/30\n",
      "12115/12115 [==============================] - 1s 121us/step - loss: 0.1043 - accuracy: 0.9557 - val_loss: 0.5462 - val_accuracy: 0.8683\n",
      "Epoch 13/30\n",
      "12115/12115 [==============================] - 1s 123us/step - loss: 0.0958 - accuracy: 0.9581 - val_loss: 0.5623 - val_accuracy: 0.8663\n",
      "Epoch 14/30\n",
      "12115/12115 [==============================] - 2s 129us/step - loss: 0.0897 - accuracy: 0.9610 - val_loss: 0.6305 - val_accuracy: 0.8660\n",
      "Epoch 15/30\n",
      "12115/12115 [==============================] - 1s 120us/step - loss: 0.0841 - accuracy: 0.9624 - val_loss: 0.6676 - val_accuracy: 0.8663\n",
      "Epoch 16/30\n",
      "12115/12115 [==============================] - 2s 125us/step - loss: 0.0793 - accuracy: 0.9644 - val_loss: 0.7074 - val_accuracy: 0.8660\n",
      "Epoch 17/30\n",
      "12115/12115 [==============================] - 1s 122us/step - loss: 0.0758 - accuracy: 0.9656 - val_loss: 0.7481 - val_accuracy: 0.8620\n",
      "Epoch 18/30\n",
      "12115/12115 [==============================] - 1s 123us/step - loss: 0.0727 - accuracy: 0.9662 - val_loss: 0.8025 - val_accuracy: 0.8594\n",
      "Epoch 19/30\n",
      "12115/12115 [==============================] - 2s 127us/step - loss: 0.0710 - accuracy: 0.9674 - val_loss: 0.8219 - val_accuracy: 0.8600\n",
      "Epoch 20/30\n",
      "12115/12115 [==============================] - 2s 145us/step - loss: 0.0695 - accuracy: 0.9686 - val_loss: 0.8215 - val_accuracy: 0.8564\n",
      "Epoch 21/30\n",
      "12115/12115 [==============================] - 1s 123us/step - loss: 0.0679 - accuracy: 0.9678 - val_loss: 0.9060 - val_accuracy: 0.8617\n",
      "Epoch 22/30\n",
      "12115/12115 [==============================] - 2s 129us/step - loss: 0.0670 - accuracy: 0.9692 - val_loss: 0.9547 - val_accuracy: 0.8594\n",
      "Epoch 23/30\n",
      "12115/12115 [==============================] - 2s 136us/step - loss: 0.0662 - accuracy: 0.9689 - val_loss: 0.9544 - val_accuracy: 0.8531\n",
      "Epoch 24/30\n",
      "12115/12115 [==============================] - 2s 131us/step - loss: 0.0651 - accuracy: 0.9698 - val_loss: 0.9817 - val_accuracy: 0.8541\n",
      "Epoch 25/30\n",
      "12115/12115 [==============================] - 2s 129us/step - loss: 0.0649 - accuracy: 0.9696 - val_loss: 0.9941 - val_accuracy: 0.8508\n",
      "Epoch 26/30\n",
      "12115/12115 [==============================] - 2s 128us/step - loss: 0.0647 - accuracy: 0.9693 - val_loss: 1.0601 - val_accuracy: 0.8574\n",
      "Epoch 27/30\n",
      "12115/12115 [==============================] - 2s 125us/step - loss: 0.0640 - accuracy: 0.9698 - val_loss: 1.0411 - val_accuracy: 0.8551\n",
      "Epoch 28/30\n",
      "12115/12115 [==============================] - 2s 128us/step - loss: 0.0635 - accuracy: 0.9698 - val_loss: 1.0429 - val_accuracy: 0.8501\n",
      "Epoch 29/30\n",
      "12115/12115 [==============================] - 2s 143us/step - loss: 0.0630 - accuracy: 0.9690 - val_loss: 1.0821 - val_accuracy: 0.8557\n",
      "Epoch 30/30\n",
      "12115/12115 [==============================] - 2s 124us/step - loss: 0.0630 - accuracy: 0.9702 - val_loss: 1.0726 - val_accuracy: 0.8564\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "history = network.fit(xtrain, train_labels, epochs = 30, batch_size = 64, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3786/3786 [==============================] - 0s 26us/step\n",
      "test_acc 0.8515583872795105\n",
      "test_loss 1.0651354923553085\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(xval, test_labels)\n",
    "print('test_acc', test_acc)\n",
    "print('test_loss', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, '--b', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss_values, '-r', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the training loss and validation loss, we can found that the training process happened overfitting strating from 4 or 5 epochs. In addition, accuracy value also indicates overfitting. Because the train accuracy at 30 epoch is 0.97, but val accuracy is 0.85. This result means that trained model cannot generalize on novel dataset.<br>\n",
    "Therefore, we suggest that epoch should be reduced at next training or we can choose the trained model from epoch 3 or epoch 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** For the MLP, we apply cross validation and show the validation loss value step by step. The curving of val_loss at part 2.3. Moreover, we test trained model on the test part of dataset and the test_acc is 0.85. Compare the results of many experiments, we found that 256-128-3 hidden layer structure can achieve the better results. However, we will do more experiments to test different the number of neurons in the hidden layer. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** For the mini-batch SGD and SGD, because we didn't get the reasonable loss value, we cannot choose the value of $\\lambda$ at this time. We will analysis the failing reason at next part. However, we provides cross validation method at here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Folder Cross Validation\n",
    "\n",
    "k = 5 \n",
    "\n",
    "num_val_samples = len(xtrain) // k \n",
    "\n",
    "for i in range(k):\n",
    "    \n",
    "    val_data = xtrain[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_label = train_y[i * num_val_samples: (i + 1) * num_val_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use above code to choose $\\lambda$ in the future experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.MLP:** MLP method got the best result. However, it happened overfitting at the early training stage. We can use a simple model or modify the different hyper-parameter to reduce the overfitting. <br>\n",
    "\n",
    "**2.Mini-Batch SGD and SGD:** Although the algorithm can be executed, the results are undesirability. We provide some possible reasons that cause the unreasonable result:<br>\n",
    "Firstly, the method of cleaning data maybe causes the problem.<br>\n",
    "Secondly, feature extraction step maybe causes the problem. For example, the setting of stop_words and word frequency lead to the more information loss.<br>\n",
    "Thirdly, the mathmatical part will lead to the error results, such as, the gradient equation includes the detailed error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue to try to solve the problem and bugs in this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
