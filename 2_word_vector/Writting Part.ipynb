{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Writting Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathmatical defination of softmax function is: $$softmax(x) = \\frac{e^xi}{\\sum _{j}e^xi}$$ <br>\n",
    "Let, $x = x + c$ <br>\n",
    "$$softmax (x + c)= \\frac{e^{(x+c)}}{\\sum _{j}e^{(x+c)}} = \\frac{e^{x+c}}{\\sum_{j}e^x*e^c} = \\frac{e^x}{\\sum_{j}e^x}$$<br>\n",
    "Therefore, $softmax(x) = softmax(x + c)$. <br> **It proves that softmax is invariant to constant o\u000b",
    "set in the input.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathmatical defination of sigmoid function is: $$sigmoid = \\frac{1}{1 + e^{-x}}$$ <br>\n",
    "The gradients of the sigmoid function is: $$\\frac{\\partial \\sigma (x)}{\\partial x} = \\frac{-e^{-x}}{(1 + e^{-x})^2} = (\\frac{1}{\\sigma (x)} - 1) * \\sigma (x)^2$$ <br>\n",
    "We can re-write the above equation as: $$\\frac{\\partial \\sigma (x)}{\\partial x} = \\sigma(x) - \\sigma(x)^2$$ <br>\n",
    "Therefore, it can be rewritten as a function of the function value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\widehat{y_{o}} = P(o | c) = \\frac{exp(u_{o}^T*V_{c})}{\\sum_{w}^{w=1}exp(u_{w}^T)V_{c}}$$ <br>\n",
    "$$J_{CE}(o, V_c, U) = CE(y,  \\widehat{y}) = -\\sum_{i}y_{i}log(\\widehat{y_{i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify the above equation: $$J_{CE}= -\\sum_{w}^{i=1}y_{i}log(\\frac{exp(u_{i}^Tv_{c})}{\\sum_{w}^{w=1}exp(u_{w}^Tv_{c})})$$ <br>\n",
    "$$J_{CE}= -\\sum_{w}^{i=1}y_{i}(u_{i}^Tv_{c} - log( \\sum_{w=1}^{w} exp(u_{w}^Tv_{c})))$$<br>\n",
    "$$J= -y_{k}(u_{k}^Tv_{c} - log( \\sum_{w=1}^{w}exp(u_{w}^Tv_{c})))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is: <br>\n",
    "$$\\frac{\\partial J}{\\partial v_{c}} = -(u_{k} - \\frac{\\sum_{w=1}^{w}exp(u_{w}^Tv_{c})u_{w}}{\\sum_{x=1}^{w}exp(u_{x}^Tv_{c})})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial v_{c}} = \\sum_{w=1}^{w} (\\widehat{y_{w}}u_{w}) - u_{k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial u_{w}} = \\frac{\\partial (-logy\\widehat{_{k}})}{\\partial u_{w}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial u_{w}} = \\frac{\\partial [-log(exp(u_{o}^Tv_{c}))+log(\\sum_{w=1}^{w}exp(u_{w}^Tv_{c}))]}{\\partial u_{w}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial u_{w}} = -v_{c}+\\frac{\\sum_{w=1}^{w}exp(u_{w}^Tv_{c})*v_{c}}{\\sum_{x=1}^{w}exp(u_{x}^Tv_{c})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial u_{w}} = -v_{c} + \\sum_{w=1}^{w}\\widehat{y_{w}}v_{c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) iii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part b),we have prove that: $$\\frac{\\partial \\sigma (x)}{\\partial x} = \\sigma(x) - \\sigma(x)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this result: $$\\frac{\\partial J}{\\partial v_{c}} = -\\frac{(\\sigma (u_{o}^Tv_{c})-\\sigma (u_{o}^Tv_{c})^2)u_{o}}{\\sigma (u_{o}^Tv_{c})} - \\sum_{k=1}^{K}\\frac{(\\sigma (u_{k}^Tv_{c})-\\sigma (u_{k}^Tv_{c})^2)(-u_{k})}{\\sigma (u_{k}^Tv_{c})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial v_{c}} =u_{o} *(\\sigma (u_{o}^Tv_{c})-1) +\\sum_{k=1}^{K}(1-\\sigma (u_{k}^Tv_{c}))(v_{c})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial u_{o}} =v_{c}*(\\sigma(u_{o}^Tv_{c})-1 )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial u_{k}} = v_{c}*(1- \\sigma(-u_{k}^Tv_{c}) )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J_{skipgram(word_{c-m...c+m})}}{\\partial v_{c}} = \\sum _{-m\\leq j\\leq m, j\\neq 0}\\frac{\\partial F(w_{c+j},\\widehat{v})}{\\partial v_{c}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J_{skipgram(word_{c-m...c+m})}}{\\partial u} = \\sum _{-m\\leq j\\leq m, j\\neq 0}\\frac{\\partial F(w_{c+j},\\widehat{v})}{\\partial u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J_{skipgram(word_{c-m...c+m})}}{\\partial v_{j}} = 0, when j \\neq c$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
